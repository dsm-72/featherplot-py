{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils\n",
    "\n",
    "> util functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os, pwd, sys, json, yaml, atexit, tempfile, inspect\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import anndata as ad\n",
    "\n",
    "from rich.repr import auto as rich_auto\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Optional, Union, Any, List, TypeAlias, Literal, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_user() -> str:\n",
    "    user = pwd.getpwuid(os.getuid())[0]\n",
    "    return user\n",
    "\n",
    "def collapse_user(path: str) -> str:\n",
    "    prefix, rest = path.split(get_user())    \n",
    "    return '~' + rest\n",
    "\n",
    "def make_temp_file(**kwargs) -> tempfile.NamedTemporaryFile:\n",
    "    temp = tempfile.NamedTemporaryFile(**kwargs)\n",
    "    @atexit.register\n",
    "    def delete_temp() -> None:\n",
    "        temp.close()\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from featherplot.types import (\n",
    "    QUADFEATHER_REQUIRED_COLUMNS,\n",
    "    QUADFEATHER_EXPECTED_COLUMNS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@rich_auto\n",
    "@dataclass\n",
    "class QuadFeatherRenamer:\n",
    "    df: Optional[pd.DataFrame]\n",
    "    \n",
    "    # whether or not to actually do renaming\n",
    "    # if False, this is equivalent to dry run\n",
    "    do: Optional[bool] = True\n",
    "    \n",
    "    # whether or not to do just required or all expected columns\n",
    "    use_all: Optional[bool] = True\n",
    "\n",
    "    # NOTE: strictly required\n",
    "    required_columns: Optional[List[str]] = field(default_factory=lambda : ['x', 'y'])\n",
    "    \n",
    "    # NOTE: assumed to be present\n",
    "    expected_columns: Optional[List[str]] = field(default_factory=lambda : ['x', 'y', 'z'])\n",
    "\n",
    "    def __rich_repr__(self):\n",
    "        yield f'df.shape({self.df.shape})'\n",
    "\n",
    "    def rename(\n",
    "        self, \n",
    "        df:Optional[pd.DataFrame]=None, do:Optional[bool]=None\n",
    "    ) -> Tuple[pd.DataFrame, dict]:\n",
    "        \n",
    "        if df is None:\n",
    "            df = self.df.copy()\n",
    "\n",
    "        if do is None:\n",
    "            do = self.do\n",
    "\n",
    "        needed = self.expected_columns if self.use_all else self.required_columns\n",
    "        missing = sorted(list(set(needed) - set(df.columns)))\n",
    "        \n",
    "        renamed = dict()\n",
    "\n",
    "        for i, col_name in enumerate(df.columns):\n",
    "            if col_name not in self.expected_columns and len(missing) > 0:\n",
    "                new_name = missing.pop(0)\n",
    "                renamed[col_name] = dict(new=new_name, old=col_name, i=i)\n",
    "        \n",
    "        name_map = {k: v['new'] for k, v in renamed.items()}\n",
    "        if not self.do:\n",
    "            return df, name_map\n",
    "        \n",
    "        df = df.rename(name_map, axis=1)\n",
    "        return df, name_map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column to Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from featherplot.types import (\n",
    "    Transform, Range, StringRange, Domain, SingleArgumentConditonal, TwoArgumentConditional,\n",
    "    Conditional, ConditionalChannel, LambdaChannel, ConstantBool, ConstantNumber, ConstantColor,\n",
    "    BooleanChannel, ConstantChannel, BasicChannel, BasicColorChannel, FunctionalChannel,\n",
    "    CategoricalColorChannel, ColorChannel, RootChannel, BasicBooleanChannel\n",
    ")\n",
    "from typing import Callable, get_args, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from featherplot.types import (\n",
    "    TypeGuardError, MissingKwargsError, LambdaChannelError,\n",
    "    ConditionalTypeGuard, TransformTypeGuard, QuadFeatherColumnTypeGuard,\n",
    "    \n",
    "    ChannelCreationError, LambdaChannelError, ConditionalChannelError,\n",
    "    ConstantChannelError, BasicChannelError, CategoricalChannelError, \n",
    "    CategoricalChannel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_lambda_channel(field: str, col:pd.Series, **kwargs) -> LambdaChannel:\n",
    "    lfunc = kwargs.get('lfunc', None)\n",
    "    if lfunc is None:\n",
    "        raise MissingKwargsError('Must provide lfunc (lambda function))')\n",
    "    try:\n",
    "        # attempt to create LambdaChannel\n",
    "        domain = (col.min().tolist(), col.max().tolist())\n",
    "        mapped = col.map(lfunc)\n",
    "        range = (mapped.min().tolist(), mapped.max().tolist())\n",
    "        channel = LambdaChannel(field=field, lfunc=lfunc, range=range, domain=domain, **kwargs)\n",
    "    except:\n",
    "        raise LambdaChannelError('Could not create LambdaChannel')\n",
    "    return channel\n",
    "\n",
    "def create_conditional_channel(field: str, col:pd.Series, **kwargs) -> ConditionalChannel:\n",
    "     # NOTE: for ConditionalChannel\n",
    "    a = kwargs.get('a', None)\n",
    "    b = kwargs.get('b', None)\n",
    "    op = kwargs.get('op', None)\n",
    "\n",
    "    if a is None and op is None:\n",
    "        raise MissingKwargsError('Must provide at least a and op (b optional)')\n",
    "\n",
    "    is_a_number = pd.api.types.is_number(a)\n",
    "\n",
    "    is_b_number_or_none = pd.api.types.is_number(b) or b is None\n",
    "\n",
    "    is_op_valid = ConditionalTypeGuard.validate(op)\n",
    "\n",
    "    if not all([is_a_number, is_b_number_or_none, is_op_valid]):\n",
    "        raise ValueError('a must be a number, b must be a number or None, op must pass ConditionalTypeGuard')\n",
    "    \n",
    "    try:\n",
    "        channel = ConditionalChannel(field=field, a=a, b=b, op=op, **kwargs)\n",
    "    except:\n",
    "        raise ConditionalChannelError('Could not create ConditionalChannel')\n",
    "\n",
    "    return channel\n",
    "\n",
    "def create_functional_channel(\n",
    "    field: str, col:pd.Series, **kwargs\n",
    ") -> FunctionalChannel:\n",
    "    lce, cce = [None, None]\n",
    "    try:\n",
    "        channel = create_lambda_channel(field, col, **kwargs)\n",
    "    except LambdaChannelError as lce:\n",
    "        lce = lce\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        channel = create_conditional_channel(field, col, **kwargs)\n",
    "    except ConditionalChannelError as cce:\n",
    "        cce = cce\n",
    "        pass\n",
    "    \n",
    "    if lce is not None and cce is not None:\n",
    "        if lce:\n",
    "            raise lce\n",
    "        if cce:\n",
    "            raise cce\n",
    "    return channel\n",
    "\n",
    "def create_boolean_channel(field:str, col:pd.Series, **kwargs) -> BooleanChannel:\n",
    "    bce, lce, cce = [None, None, None] \n",
    "\n",
    "    # NOTE: try to create Boolean channel\n",
    "    try:\n",
    "        if col.dtype == 'bool':\n",
    "            # ConstantBool(constant='boolean')\n",
    "            channel = BasicBooleanChannel(field=field, constant='boolean', **kwargs)\n",
    "            return channel\n",
    "    except:\n",
    "        bce = ConstantChannelError('Could not create ConstantBool')\n",
    "\n",
    "    if bce is not None:\n",
    "        # NOTE: try to create Fucntional Channel instead\n",
    "        try:\n",
    "            channel = create_functional_channel(field, col, **kwargs)\n",
    "        except LambdaChannelError as lce:\n",
    "            lce = lce\n",
    "            pass\n",
    "        except ConditionalChannelError as cce:\n",
    "            cce = cce\n",
    "            pass\n",
    "\n",
    "        if lce is not None or cce is not None:\n",
    "            if lce:\n",
    "                raise lce\n",
    "            if cce:\n",
    "                raise cce\n",
    "        \n",
    "        return channel\n",
    "    return channel\n",
    "        \n",
    "def create_color_channel(field:str, col:pd.Series, **kwargs) -> ColorChannel:\n",
    "    dtype = col.dtype.name\n",
    "    # NOTE: force strings to be categories\n",
    "    if dtype == 'object':\n",
    "        col = col.astype('category')\n",
    "        dtype = col.dtype.name\n",
    "\n",
    "    try:\n",
    "        if dtype == 'category':\n",
    "            col = col.cat.as_ordered()\n",
    "            domain = int(col.cat.codes.min().tolist()), int(col.cat.codes.max().tolist())\n",
    "\n",
    "            cats = col.cat.categories.tolist() if len(col.cat.categories) <= 10 else None\n",
    "            channel = CategoricalColorChannel(field=field, domain=domain, categories=cats, **kwargs)        \n",
    "            return channel\n",
    "        \n",
    "    except:\n",
    "        raise CategoricalChannelError('Could not create CategoricalColorChannel')\n",
    "    \n",
    "def create_root_channel(field:str, col:pd.Series, **kwargs) -> RootChannel:\n",
    "    dtype = col.dtype.name\n",
    "    channel = None\n",
    "    match dtype:\n",
    "        case 'bool':\n",
    "            channel = create_boolean_channel(field, col, **kwargs)\n",
    "        \n",
    "        case 'category':\n",
    "            # NOTE: this solve a lot of issues with\n",
    "            # distinguishing between BasicColorChannel and CategoricalColorChannel\n",
    "            # as BasicColorChannel has a *NUMERIC* domain and \n",
    "            # CategoricalColorChannel has strings as a domain\n",
    "            # category works with both\n",
    "            channel = create_color_channel(field, col, **kwargs)\n",
    "        \n",
    "        # NOTE: this forces strings to be categories\n",
    "        case 'object':\n",
    "            channel = create_color_channel(field, col, **kwargs)\n",
    "        \n",
    "        case _:\n",
    "            # NOTE: not a bool, not a category, not a string, must be numeric\n",
    "            # pd.api.types.is_number(a)\n",
    "            channel = BasicChannel(field=field, domain=(col.min().tolist(), col.max().tolist()), **kwargs)            \n",
    "    \n",
    "    if channel is None:\n",
    "        raise ChannelCreationError('Could not create RootChannel')\n",
    "    return channel\n",
    "\n",
    "@rich_auto\n",
    "@dataclass\n",
    "class SeriesToChannel:\n",
    "    series: pd.Series\n",
    "    is_sidecar: Optional[bool] = False\n",
    "    alt_name: Optional[str] = None\n",
    "\n",
    "    def convert(self):\n",
    "        if self.alt_name is not None:\n",
    "            return create_root_channel(self.series.name, self.series, human=self.alt_name)\n",
    "        return create_root_channel(self.series.name, self.series)\n",
    "    \n",
    "    def is_category(self):\n",
    "        channel = self.convert()\n",
    "        return isinstance(channel, (CategoricalColorChannel, CategoricalChannel, BasicColorChannel))\n",
    "    \n",
    "    def as_category(self):\n",
    "        self.series = self.series.astype('category')\n",
    "        return self\n",
    "    \n",
    "    def to(self, to:str, **kwargs):\n",
    "        alt_name = kwargs.get('alt_name', None)\n",
    "        if alt_name is None and self.alt_name is not None:\n",
    "            kwargs['alt_name'] = self.alt_name\n",
    "         \n",
    "        match to:\n",
    "            case 'lambda':\n",
    "                channel = create_lambda_channel(self.series.name, self.series, **kwargs)\n",
    "            case 'conditional':\n",
    "                channel = create_conditional_channel(self.series.name, self.series, **kwargs)\n",
    "            case 'functional':\n",
    "                channel = create_functional_channel(self.series.name, self.series, **kwargs)\n",
    "            case 'boolean':\n",
    "                channel = create_boolean_channel(self.series.name, self.series, **kwargs)\n",
    "            case 'color':\n",
    "                channel = create_color_channel(self.series.name, self.series, **kwargs)\n",
    "            case 'root':\n",
    "                channel = create_root_channel(self.series.name, self.series, **kwargs)\n",
    "            case _:\n",
    "                raise ValueError(f'Unknown channel type {to}')\n",
    "        return channel\n",
    "    \n",
    "    def as_lambda(self, **kwargs):\n",
    "        return self.to('lambda', **kwargs)\n",
    "    \n",
    "    def as_conditional(self, **kwargs):\n",
    "        return self.to('conditional', **kwargs)\n",
    "    \n",
    "    def as_functional(self, **kwargs):\n",
    "        return self.to('functional', **kwargs)\n",
    "    \n",
    "    def as_boolean(self, **kwargs):\n",
    "        return self.to('boolean', **kwargs)\n",
    "    \n",
    "    def as_color(self, **kwargs):\n",
    "        return self.to('color', **kwargs)\n",
    "    \n",
    "    def as_root(self, **kwargs):\n",
    "        return self.to('root', **kwargs)\n",
    "    \n",
    "    def valid_types(self, **kwargs) -> Tuple[List[str], List[str]]:\n",
    "        errors = []\n",
    "        valids = []\n",
    "        for t in ['lambda', 'conditional', 'functional', 'boolean', 'color', 'root']:\n",
    "            try:\n",
    "                self.to(t, **kwargs)\n",
    "                valids.append(t)\n",
    "            except:\n",
    "                errors.append(t)\n",
    "        return valids, errors\n",
    "\n",
    "    def to_meta(self, **kwargs) -> dict:\n",
    "        channel = self.convert()\n",
    "        return channel.to_meta(**kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame to MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@rich_auto\n",
    "@dataclass\n",
    "class DataFrameToMetadata:\n",
    "    df: pd.DataFrame\n",
    "    sidecars: Optional[List[str]] = field(default_factory=list)\n",
    "    embedding: Optional[List[str]] = field(default_factory=lambda : ['x', 'y', 'z'])\n",
    "    alt_names: Optional[Dict[str, str]] = field(default_factory=dict)\n",
    "    \n",
    "    include_index: Optional[bool] = True\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if not self.sidecars:\n",
    "            self.sidecars = self._default_sidecars()\n",
    "\n",
    "        if not self.embedding:\n",
    "            self.embedding = ['x', 'y', 'z']\n",
    "        else:\n",
    "            if not all([e in self.embedding for e in ['x', 'y', 'z']]):\n",
    "                raise ValueError('Must have x, y, z in embedding')\n",
    "            \n",
    "    def _default_sidecars(self) -> List[str]:\n",
    "        return sorted(list(set(self.df.columns) - set(self.embedding)))\n",
    "    \n",
    "    def _do_one(self, name:str, col:pd.Series, is_index:bool=False) -> Tuple[Union[Any, None], Union[Dict[str, Any], None]]:\n",
    "        success = None\n",
    "        failure = None\n",
    "        \n",
    "        is_sidecar = name in self.sidecars and not name in self.embedding\n",
    "        alt_name = self.alt_names.get(name, None)\n",
    "        \n",
    "        try:\n",
    "            s2c = SeriesToChannel(col, is_sidecar, alt_name)\n",
    "            channel = s2c.convert()\n",
    "            \n",
    "            # NOTE: if channel COULD be categorical force it to be a category\n",
    "            if (not is_index and self.df.index.name != name) and s2c.is_category():\n",
    "                channel = s2c.as_category().convert()\n",
    "                self.df.loc[:, name] = s2c.series.values\n",
    "\n",
    "\n",
    "            success = channel\n",
    "        except Exception as e:\n",
    "            failure = dict(name=name, is_sidecar=is_sidecar, alt_name=alt_name, error=e)\n",
    "\n",
    "        return success, failure\n",
    "\n",
    "    def convert(self) -> Tuple[dict, List[Dict[str, Dict[str, Any]]]]:\n",
    "        failed = []\n",
    "        channels = {}\n",
    "\n",
    "        if self.include_index:\n",
    "            name = 'index' if self.df.index.name is None else self.df.index.name\n",
    "            succ, fail = self._do_one(name, pd.Series(self.df.index), is_index=True)\n",
    "            if succ is not None:\n",
    "                channels[name] = succ\n",
    "            else:\n",
    "                failed.append(fail)\n",
    "\n",
    "        for i, (name, col) in enumerate(self.df.iteritems()):            \n",
    "            succ, fail = self._do_one(name, col)\n",
    "            if succ is not None:\n",
    "                if name not in channels:\n",
    "                    channels[name] = succ                \n",
    "            else:\n",
    "                failed.append(fail)\n",
    "                \n",
    "        return channels, failed\n",
    "    \n",
    "    def to_dict(self) -> dict:\n",
    "        channels, failed = self.convert()\n",
    "        index = self.df.index.name if self.df.index.name is not None else 'index'\n",
    "        n_points = self.df.shape[0]\n",
    "        columns_metadata = dict()\n",
    "        for k, v in channels.items():\n",
    "            columns_metadata[k] = v.to_dict()\n",
    "\n",
    "        d = dict(\n",
    "            index=index,\n",
    "            n_points=n_points,\n",
    "            embedding=self.embedding,\n",
    "            sidecars=self.sidecars,\n",
    "            columns_metadata=columns_metadata,\n",
    "            tiles_dir=None\n",
    "        )\n",
    "        return d\n",
    "    \n",
    "    def to_meta(self) -> dict:\n",
    "        channels, failed = self.convert()\n",
    "        index = self.df.index.name if self.df.index.name is not None else 'index'\n",
    "        n_points = self.df.shape[0]\n",
    "        columns_metadata = dict()\n",
    "        for k, v in channels.items():\n",
    "            columns_metadata[k] = v.to_meta()\n",
    "\n",
    "        d = dict(\n",
    "            index=index,\n",
    "            n_points=n_points,\n",
    "            embedding=self.embedding,\n",
    "            sidecars=self.sidecars,\n",
    "            columns_metadata=columns_metadata,\n",
    "            tiles_dir=None\n",
    "        )\n",
    "        return d\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AnnData"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mocking AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@rich_auto\n",
    "@dataclass\n",
    "class MockSingleCellData:\n",
    "    label: Optional[str] = 'barcode'\n",
    "    c_str: Optional[str] = 'condition'\n",
    "    n_str: Optional[str] = 'norm'\n",
    "    \n",
    "    n_genes: Optional[int] = 100\n",
    "    n_points: Optional[int] = 1000\n",
    "    emb_name: Optional[str] = 'MOCK'\n",
    "    emb_dims: Optional[int] = 3\n",
    "    n_conditions: Optional[int] = 4\n",
    "    hvg_ratio: Optional[int] = 5\n",
    "    \n",
    "    @property\n",
    "    def emb_cols(self):\n",
    "        arr = list(map(lambda i: f'{self.emb_name}_{i}', np.arange(self.emb_dims)))\n",
    "        return np.array(arr)\n",
    "    \n",
    "    @property\n",
    "    def gene_symbols(self):\n",
    "        try:\n",
    "            return self._gene_symbols\n",
    "        except AttributeError:\n",
    "            _str = 'gene_symbol'\n",
    "            name = f'{_str}s'\n",
    "            func = lambda i: f'{_str} {i}'\n",
    "            series = pd.Series(np.arange(self.n_genes), name=name).map(func)            \n",
    "            self._gene_symbols = series\n",
    "        return self._gene_symbols\n",
    "    \n",
    "    @property\n",
    "    def is_hvg_gene(self):\n",
    "        try:\n",
    "            return self._is_hvg\n",
    "        except AttributeError:\n",
    "            is_hvg = pd.Series(np.arange(self.n_genes), name='is_hvg').map(lambda i: i % self.hvg_ratio)\n",
    "            is_hvg.index = self.gene_symbols\n",
    "            self._is_hvg = is_hvg\n",
    "        return self._is_hvg\n",
    "\n",
    "    @property\n",
    "    def labels(self) -> pd.Series:\n",
    "        try:\n",
    "            return self._labels\n",
    "        except AttributeError:\n",
    "            _str = self.label\n",
    "            name = f'{_str}s'\n",
    "            func = lambda i: f'{_str} {i}'\n",
    "            series = pd.Series(np.arange(self.n_points), name=name).map(func)\n",
    "            self._labels = series\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def conditions(self) -> pd.Series:\n",
    "        try:\n",
    "            return self._conditions\n",
    "        except AttributeError:\n",
    "            _str = self.c_str\n",
    "            name = f'{_str}s'\n",
    "            func = lambda i: f'{_str} {i % self.n_conditions}'\n",
    "            series = pd.Series(np.arange(self.n_points), name=name).map(func)\n",
    "            series.index = self.labels\n",
    "            self._conditions = series\n",
    "        return self._conditions\n",
    "    \n",
    "    @property\n",
    "    def df_emb(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            return self._df_emb\n",
    "        except AttributeError:\n",
    "            df_emb = pd.DataFrame(\n",
    "                np.random.randn(self.n_points, self.emb_dims), \n",
    "                index=self.labels, columns=self.emb_cols\n",
    "            )\n",
    "            df_emb = df_emb.join(self.conditions)\n",
    "            self._df_emb = df_emb\n",
    "        return self._df_emb\n",
    "    \n",
    "    @property\n",
    "    def df_cnt(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            return self._df_cnt\n",
    "        except AttributeError:\n",
    "            df_cnt = pd.DataFrame(\n",
    "                np.random.randn(self.n_points, self.n_genes), \n",
    "                index=self.labels, columns=self.gene_symbols\n",
    "            )\n",
    "            self._df_cnt = df_cnt\n",
    "        return self._df_cnt\n",
    "    \n",
    "    @property\n",
    "    def df_nrm(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            return self._df_nrm\n",
    "        except AttributeError:\n",
    "            df_nrm = pd.DataFrame(\n",
    "                np.random.randn(self.n_points, self.n_genes), \n",
    "                index=self.labels, columns=self.gene_symbols\n",
    "            )\n",
    "            self._df_nrm = df_nrm\n",
    "        return self._df_nrm\n",
    "\n",
    "    @property\n",
    "    def x_emb(self):\n",
    "        return f'X_{self.emb_name.lower()}'\n",
    "    \n",
    "    @property\n",
    "    def x_norm(self):\n",
    "        return f'X_{self.n_str.lower()}'\n",
    "\n",
    "    @property\n",
    "    def adata(self):\n",
    "        try:\n",
    "            return self._adata\n",
    "        except AttributeError:\n",
    "            _str = self.label\n",
    "            label_name = f'{_str}s' # barcodes\n",
    "\n",
    "            _str = self.c_str\n",
    "            conds_name = f'{_str}s' # conditions\n",
    "\n",
    "            obs = self.df_emb.reset_index()\n",
    "            obs = obs[[label_name, conds_name]].set_index(label_name, drop=False)\n",
    "\n",
    "            obsm = dict()\n",
    "            obsm[self.x_emb] = self.df_emb.drop(columns=conds_name)\n",
    "\n",
    "            layers = dict()\n",
    "            layers[self.x_norm] = self.df_nrm\n",
    "\n",
    "            adata = ad.AnnData(\n",
    "                X = self.df_cnt,\n",
    "                obs = obs,\n",
    "                var = pd.DataFrame(self.is_hvg_gene, index=self.gene_symbols),\n",
    "                obsm = obsm,\n",
    "                layers = layers,\n",
    "            )\n",
    "            \n",
    "            self._adata = adata\n",
    "\n",
    "        return self._adata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing AnnData back to DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "@rich_auto\n",
    "@dataclass\n",
    "class AnnDataProcessor:\n",
    "    adata: ad.AnnData\n",
    "    x_emb: str = 'X_phate'\n",
    "    layer: Optional[str] = None\n",
    "    \n",
    "\n",
    "    def get_sidecars(self):\n",
    "        layer = self.adata.layers.get(self.layer, None)\n",
    "\n",
    "\n",
    "        if layer is None:\n",
    "            layer = self.adata.X\n",
    "\n",
    "        if hasattr(layer, 'toarray'):\n",
    "            layer = layer.toarray()\n",
    "\n",
    "        if hasattr(layer, 'todense'):\n",
    "            layer = layer.todense()\n",
    "\n",
    "        df = pd.DataFrame(\n",
    "            layer,\n",
    "            columns=self.adata.var.index,\n",
    "            index=self.adata.obs.index\n",
    "        )\n",
    "        return df\n",
    "    \n",
    "    @property\n",
    "    def emb_name(self):\n",
    "        return self.x_emb.replace('X_', '').upper()\n",
    "\n",
    "    def get_embedding(self, add_conditions:bool=False):\n",
    "        emb = self.adata.obsm.get(self.x_emb, None)\n",
    "        cols = [f'{self.emb_name}_{i+1}' for i in range(emb.shape[1])]\n",
    "        df = pd.DataFrame(\n",
    "            emb, columns=cols, \n",
    "            index=self.adata.obs.index\n",
    "        )\n",
    "        if add_conditions and 'conditions' in self.adata.obs.columns:        \n",
    "            df.loc[:, 'conditions'] = self.adata.obs.conditions        \n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
